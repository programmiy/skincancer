import time
import streamlit as st
import os
import datetime
import numpy as np
import tensorflow as tf
from PIL import Image

VISITOR_COUNT_DIR = "visitor_counts"





       
        
        




def get_current_date():
    now = datetime.datetime.now()
    return now.strftime("%Y-%m-%d")






def intro():
    import streamlit as st
    
    def increase_visitor_count():
        current_date = get_current_date()
        file_path = os.path.join(VISITOR_COUNT_DIR, f"{current_date}.txt")

        if not os.path.exists(file_path):
            with open(file_path, "w") as f:
                f.write("0")

        with open(file_path, "r+") as f:
            count = int(f.read())
            count += 1
            f.seek(0)
            f.write(str(count))
    increase_visitor_count()
    st.write("# í”¼ë¶€ì•” ê²€ì‚¬ë¥¼ ìœ„í•œ í˜ì´ì§€ì— ì˜¨ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤ğŸ‘¨â€âš•ï¸")
    st.markdown("""
    **ğŸ‘ˆ ì‚¬ì´ë“œë°”ë¥¼ í´ë¦­í•´ì„œ** ë” ë§ì€ ì •ë³´ë¥¼ í™•ì¸í•˜ì„¸ìš”!
    """)
    st.sidebar.success("ì›í•˜ëŠ” ì •ë³´ë¥¼ í™•ì¸í•˜ì„¸ìš”")
    code = '''powered by Streamlit'''
    st.code(code, language='java')
    st.subheader("âš ï¸ ì˜í•™ì  ì§€ì‹ì„ ëŒ€ì²´í•˜ëŠ” ê²ƒì´ ì•„ë‹™ë‹ˆë‹¤ ")
    st.subheader("âš ï¸ ì ì¬ì ì¸ í”¼ë¶€ ë¬¸ì œë¥¼ ì‰½ê²Œ íŒŒì•…í•˜ëŠ” ë„ì›€ì„ ë°›ì„ ìˆ˜ ìˆë„ë¡ ë•ëŠ” ë„êµ¬ë¼ëŠ” ì ì— ìœ ì˜í•´ì•¼ í•©ë‹ˆë‹¤")

    from markdownlit import mdlit

    st.success("ì œì‘ì— ë„ì›€ì„ ì¤€ ì‚¬ì´íŠ¸ë“¤")

    mdlit(
        """




@(https://streamlit.io)

[orange]Inspired by[/orange] @(https://huggingface.co/ilhamstoked)

""")
    

    
    mdlit(
        """[blue]Our[/blue] [green]Repository[/green]      @(https://github.com/programmiy/skincancer)
        """
    )
    

    from streamlit_extras.badges import badge

    badge(type="github", name="programmiy/skincancer")
    def get_visitor_count(date):
        file_path = os.path.join(VISITOR_COUNT_DIR, f"{date}.txt")

        if not os.path.exists(file_path):
            return 0

        with open(file_path, "r") as f:
            count = int(f.read())
            return count
    
    date = get_current_date()   
    user = get_visitor_count(date)
    
    
    def get_delta(now): #íŒŒë¼ë¯¸í„° ì—†ì• ê¸°, í˜¹ì€  get_current_date ìˆ˜ì •
        now = datetime.datetime.now()
        delta = now - datetime.timedelta(days= 1)
        delta = delta.strftime("%Y-%m-%d") # get_current_dateë‘ ê²¹ì¹¨
        
        return delta
        
    def user_check(date):
        delta = get_delta(date)
        if get_visitor_count(date) - get_visitor_count(delta) < 0:
            return 0
        else:
            return get_visitor_count(date) - get_visitor_count(delta)
    
    
    st.metric(label="ë°©ë¬¸ì ìˆ˜", value=user, delta=user_check(date), help="í•˜ë£¨ ë™ì•ˆ ì´ ì‚¬ì´íŠ¸ì— ë°©ë¬¸í•œ ë°©ë¬¸ì ìˆ˜ì…ë‹ˆë‹¤.")

    from streamlit_extras.metric_cards import style_metric_cards
    style_metric_cards()
    



def usage():

    

    st.write("ì‚¬ìš©ë²• ì†Œê°œ")

def based_information():
    
    from markdownlit import mdlit


    
    
    
  

    st.image('https://upload.wikimedia.org/wikipedia/commons/thumb/b/bb/Wikipedia_wordmark.svg/600px-Wikipedia_wordmark.svg.png')
    st.header("ì´ ì•±ì—ì„œ íŒë³„ ê°€ëŠ¥í•œ ì•”ì˜ ì¢…ë¥˜ë“¤")
    # st.write(f"- í¸í‰ ì„¸í¬ì•” {Squamous_cell}")
    mdlit(
        """- @([orange]í¸í‰ ì„¸í¬ì•”[/orange])(https://en.wikipedia.org/wiki/Squamous-cell_carcinoma) ->  ì‚¬ë§ˆê·€ë‚˜ ë¬¼ì§‘ ë“±ì˜ í˜•íƒœë‚˜ ê²€ì€ìƒ‰ ë©ì–´ë¦¬ê°€ ìœµê¸°í•˜ì—¬ ë‚˜íƒ€ë‚˜ëŠ” í”¼ë¶€ì•”
        """
    )
    mdlit(
        """- @([orange]ê¸°ì € ì„¸í¬ì•”[/orange])(https://en.wikipedia.org/wiki/Basal-cell_carcinoma) ->  í”¼ë¶€ ì•ˆì—ì„œ ë¶€í„° ë°œì „í•˜ëŠ” í”¼ë¶€ì•”, ê¸°ì €ì¸µì´ë‚˜ ëª¨ë‚­ ë“±ì„ êµ¬ì„±í•˜ëŠ” ì„¸í¬ê°€ ì•…ì„±í™”í•œÂ ì¢…ì–‘
        """
    )

    mdlit(
        """- @([orange]ì–‘ì„± ê°í™”ì¦[/orange])(https://en.wikipedia.org/wiki/Seborrheic_keratosis) ->  ê²€ë²„ì„¯ì´ë¼ê³  ë¶€ë¥´ëŠ”, í‘œí”¼ ê°ì§ˆì¸µì— êµ¬ì„±ëœ ì‚¬ë§ˆê·€ ëª¨ì–‘ì˜ í”í•œ í”¼ë¶€ì–‘ì„±ì¢…ì–‘ì´ë‹¤. """
    )
    
    mdlit(
        """- @([orange]í”¼ë¶€ ì„¬ìœ ì¢…[/orange])(https://en.wikipedia.org/wiki/Dermatofibroma) ->  í”¼ë¶€ê°€ ìƒì²˜ê°€ ë‚œ ë’¤ì— ìì£¼ ë°œìƒí•˜ëŠ” ì–‘ì„± ì¢…ì–‘ """
    )
    mdlit(
        """- @([orange]ë©œë¼ë‹Œ ì„¸í¬ ëª¨ë°˜[/orange])(https://en.wikipedia.org/wiki/Melanocytic_nevus) ->  í‘ìƒ‰ì¢…ê³¼ ê°€ì¥ ë¹„ìŠ·í•œ ì–‘ì„± ì¢…ì–‘ """
    )
    mdlit(
        """- @([orange]í‘ìƒ‰ì¢…[/orange])(https://en.wikipedia.org/wiki/Melanoma) -> ë©œë¼ë‹Œ ì„¸í¬ ëª¨ë°˜ì´ ë¹„ëŒ€ì¹­ì´ê±°ë‚˜ ê²½ê³„ê°€ ëšœë ·í•˜ì§€ ì•Šì€ ì•…ì„± ì¢…ì–‘  """
    )
    mdlit(
        """- @([orange]í˜ˆê´€ ë³‘ë³€[/orange])(https://en.wikipedia.org/wiki/Vascular_anomaly)  -> ëª¨ì„¸í˜ˆê´€ì˜ í™•ì¥ìœ¼ë¡œ ìƒê¸°ëŠ” ë³‘ë³€, í”¼ë¶€ì•”ì€ ì•„ë‹ˆë©°  ë³´ë¼ìƒ‰, ìì£¼ìƒ‰, ë¹¨ê°„ìƒ‰ ë“±  ìƒ‰ê¹”ì€ ë‹¤ì–‘í•œ í¸"""
    )




    # ì´ë¯¸ì§€ ì—…ìŠ¤ì¼€ì¼ë§ 


   # default upsc

    # Define a function to resize the input image
    # def resize_image(image):
    #     # Resize the image to 150x150 pixels
    #     resized_image = tf.image.resize(image, [150, 150])
        
    #     return resized_image.numpy()


    # replace upsc


def resize_image(image):
    
    """
    Pads the input image and resizes it to 150x150 pixels.

    Args:
        image (tf.Tensor): The input image tensor.

    Returns:
        tf.Tensor: The padded and resized image tensor.

    Raises:
        ValueError: If the input image has a shape smaller than 150x150 pixels.
    """
    # Get the original image shape
    original_shape = tf.shape(image)
    
    # Calculate the padding amounts
    height_pad = (original_shape[0] - 150) // 2
    width_pad = (original_shape[1] - 150) // 2
    
    # Pad the image
    padded_image = tf.pad(image, [[height_pad, height_pad], [width_pad, width_pad], [0, 0]])
    
    # Resize the padded image to 150x150 pixels
    resized_image = tf.image.resize(padded_image, [150, 150])

    
    return resized_image

    # Define a function to run inference on the TensorFlow Lite model
def classify_image(image):
        
    """
        Runs inference on the input image using the provided interpreter and model details.

        Args:
            image (numpy.ndarray): The input image array.
            interpreter (tensorflow.lite.Interpreter): The TensorFlow Lite interpreter.
            input_details (list): A list of input details dictionaries for the interpreter.
            output_details (list): A list of output details dictionaries for the interpreter.

        Returns:
            tuple: A tuple containing the output probabilities and the classification duration.

        Raises:
            ValueError: If the input image has an invalid format or shape.
        
    """            
        # Load TensorFlow Lite model
    interpreter = tf.lite.Interpreter(model_path="models/mobilenet_v1_1.0_224_quant.tflite")
    interpreter.allocate_tensors()
    interpreter = tf.lite.Interpreter(model_path="models/InceptionResNetV2Skripsi.tflite")
    interpreter.allocate_tensors()

    # Get input and output tensors
    input_details = interpreter.get_input_details()
    output_details = interpreter.get_output_details()
    # Pre-process the input image
    resized_image = resize_image(image)
    

    input_data = np.expand_dims(resized_image, axis=0).astype(np.float32)
    interpreter.set_tensor(input_details[0]['index'], input_data)
    
    
    
    # Run inference
    with st.spinner('ë¶„ì„ ì¤‘...'):
        start_time = time.time()
        interpreter.invoke()
        end_time = time.time()
        
    
    # Calculate the classification duration
    classifying_duration = end_time - start_time
   
    # Get the output probabilities
    output_data = interpreter.get_tensor(output_details[0]['index'])
    

    return output_data[0], classifying_duration
def testing():


    st.warning("ì´ë¯¸ì§€ ì œì¶œ ë°©ì‹ì„ ê³¨ë¼ì£¼ì„¸ìš”")

    upload = st.checkbox("íŒŒì¼ ì—…ë¡œë“œí•˜ê¸°")
    take = st.checkbox("ì‚¬ì§„ ì°ê¸°")
    if upload:
        image = st.file_uploader(label="íŒŒì¼ ì—…ë¡œë“œí•˜ê¸°", type=["jpg", "jpeg", "png"])
        if image is not None:
            compute_analysis(image)
            # # image_upscailing(image)
            # image = np.array(Image.open(image).convert("RGB"))
            # preresize = image
            # st.code("ì‘ì—…ì— ì‚¬ìš©ëœ ì´ë¯¸ì§€", language= "java")
            # st.image(image, width=150)

            # # Run inference on the input image
            # probs, classifying_duration = classify_image(image)

            
            # # Display the classification duration
            # st.success(f"ì†Œìš” ì‹œê°„: {classifying_duration:.4f} ì´ˆ", icon="âœ…")
            
            # # Display the top 3 predictions
            # top_3_indices = np.argsort(probs)[::-1][:3]
            
            # st.write("ì˜ˆì¸¡ë˜ëŠ” ìƒìœ„ 3ê°œì˜ ì§•í›„:")
            # for i in range(3):
            #     st.write("%d. %s (%.2f%%)" % (i + 1, labels[top_3_indices[i]], probs[top_3_indices[i]] * 100))
            # st.divider()
            # st.code("ìœ ì‚¬ì  ë¹„êµ", language='python')
            
            # classification(preresize)
                

    elif take:
        image = st.camera_input(label="ì‚¬ì§„ ì°ê¸°", help="ì›¹ìº  ì§€ì›")
        if image is not None:
            compute_analysis(image)

def collapse(img_bytes_array, similarity_list): # nested collapse
    
    
    i = 0
    for img_bytes, similarity in zip(img_bytes_array, similarity_list):
        st.image(Image.open(img_bytes), caption=f'ë¹„ìŠ·í•œ ì´ë¯¸ì§€ #{i+1} (ìœ ì‚¬ë„: {similarity:.2f})')
        i +=1 
            # ë‹¤ìš´ë¡œë“œ

def compute_analysis(image): # ì¤‘ë³µì‘ì—… ì¼ê´„ì²˜ë¦¬ìš©

    """
    Computes analysis for the input image, including classification and visual comparison.

    Args:
        image (str): The path to the input image.

    Returns:
        None
    """    
    import numpy as np
    
    from PIL import Image
    # Define the labels for the 7 classes
    labels = ['í¸í‰ ì„¸í¬ì•”', 'ê¸°ì € ì„¸í¬ì•”', 'ì–‘ì„± ê°í™”ì¦', 'í”¼ë¶€ ì„¬ìœ ì¢…', 'í‘ìƒ‰ì¢…', 'ë©œë¼ë‹Œ ì„¸í¬ ëª¨ë°˜', 'í˜ˆê´€ ë³‘ë³€ì¦']
        
    image = np.array(Image.open(image).convert("RGB"))
    preresize = image
            

    # Run inference on the input image
    probs, classifying_duration = classify_image(image) # + upsc

            
    # Display the classification duration
    st.success(f"ì†Œìš” ì‹œê°„: {classifying_duration:.4f} ì´ˆ", icon="âœ…")

    # Display the top 3 predictions
    top_3_indices = np.argsort(probs)[::-1][:3]
            
    st.write("ì˜ˆì¸¡ë˜ëŠ” ìƒìœ„ 3ê°œì˜ ì§•í›„:")
    for i in range(3):
        st.write("%d. %s (%.2f%%)" % (i + 1, labels[top_3_indices[i]], probs[top_3_indices[i]] * 100))
    with st.expander("ìœ ì‚¬ì  ë¹„êµí•´ë³´ê¸° "):
            
        st.header("ìœ ì‚¬ì  ë¹„êµ")
        imgarray, similarity_list = classification(preresize)
                
                # Convert HTML to image using imgkit
                

        wannasee = st.button("ê²°ê³¼ ì§ì ‘ ë³´ê¸°")
        if wannasee:
                    
            collapse(imgarray, similarity_list)
                
    st.button("ë‹¤ì‹œë³´ê¸°")

def classification(compare_img):
    import numpy as np
    import cv2
    
    import glob
    import io
    from PIL import Image

    import base64
    img_list = glob.glob('cancer/*.jpg')
    compare_img = np.array(compare_img)
    compare_img = cv2.cvtColor(compare_img, cv2.COLOR_RGB2BGR) 
    

    orb = cv2.ORB_create()
    kp2, des2 = orb.detectAndCompute(compare_img, None)

    matches_data = []
    for img_path in img_list:
        base_img = cv2.imread(img_path, 0)
        
        kp1, des1 = orb.detectAndCompute(base_img, None)

        bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)
        matches = bf.match(des1, des2)
        if matches:
            similarity = sum(match.distance for match in matches) / len(matches)
        else:
            similarity = 0

        matches_data.append((img_path, similarity))

    # sort matches by similarity score
    matches_data.sort(key=lambda x: x[1], reverse=True)
    
    # get top 5 matches
    top_matches = matches_data[:5]

    imgarray = []
    similarity_list = []
    # Generate HTML content for download
    html_content = "<html><body>"
    for i, (img_path, similarity) in enumerate(top_matches):
        base_img = cv2.imread(img_path)
        kp1, des1 = orb.detectAndCompute(base_img, None)

        bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)
        matches = bf.match(des1, des2)
        matches = sorted(matches, key=lambda x: x.distance)

        img3 = cv2.drawMatches(base_img, kp1, compare_img, kp2, matches[:10], None, flags=2)
        img3_rgb = cv2.cvtColor(img3, cv2.COLOR_BGR2RGB)
        
        

        # Save the image as BytesIO object
        img_bytes = io.BytesIO()
        Image.fromarray(img3_rgb).save(img_bytes, format='PNG')
        img_data = img_bytes.getvalue()
        imgarray.append(img_bytes)
        similarity_list.append(similarity)

        # Add the image to the HTML content
        html_content += f"<h3>ë¹„ìŠ·í•œ ì´ë¯¸ì§€ #{i+1} (ìœ ì‚¬ë„: {similarity:.2f})</h3>"
        html_content += f"<img src='data:image/png;base64,{base64.b64encode(img_data).decode()}'/><br><br>"

    html_content += "</body></html>"

    # Download button
    st.download_button("ê²°ê³¼ë¥¼ htmlë¡œ ë‹¤ìš´ë¡œë“œ ë°›ê¸° ", data=html_content, file_name="ë¶„ì„ ê²°ê³¼.html", mime="text/html")

    return  imgarray, similarity_list



    # # Display the matched images
    # for i, (img_path, similarity) in enumerate(top_matches):
    #     base_img = cv2.imread(img_path)
    #     kp1, des1 = orb.detectAndCompute(base_img, None)

    #     bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)
    #     matches = bf.match(des1, des2)
    #     matches = sorted(matches, key=lambda x: x.distance)

    #     img3 = cv2.drawMatches(base_img, kp1, compare_img, kp2, matches[:10], None, flags=2)
        
    #     # Create a Streamlit image object from the OpenCV image
    #     # st.write(f"Base image shape: {base_img.shape}")
    #     # st.write(f"Compare image shape: {compare_img.shape}")
    #     img_bytes = cv2.imencode('.png', img3)[1].tobytes()
    #     st.image(Image.open(io.BytesIO(img_bytes)), caption=f'ë¹„ìŠ·í•œ ì´ë¯¸ì§€ #{i+1} (ìœ ì‚¬ë„: {similarity:.2f})') # ë¹„í™œì„±í™”

# í˜ì´ì§€ êµ¬ì„± 

page_names_to_funcs = {
    "í™ˆ": intro,
    "í”¼ë¶€ì•”ì— ëŒ€í•œ ê¸°ë³¸ ì •ë³´": based_information,
    "ì‚¬ìš©ë²•": usage,
    "ê²€ì‚¬í•˜ê¸°": testing
}

page_name = st.sidebar.selectbox("ì›í•˜ëŠ” í˜ì´ì§€ë¥¼ ê³ ë¥´ì„¸ìš”", page_names_to_funcs.keys())



page_names_to_funcs[page_name]()
