import PIL
from cv2 import normalize
import streamlit as st
import os
import datetime
VISITOR_COUNT_DIR = "visitor_counts"



def classification(compare_img):
    import numpy as np
    import cv2
    
    import glob
    import io
    from PIL import Image
    from reportlab.pdfgen import canvas
    from reportlab.pdfgen import canvas
    from reportlab.pdfbase import pdfmetrics
    from reportlab.pdfbase.ttfonts import TTFont
    import base64
    img_list = glob.glob('cancer/*.jpg')
    compare_img = np.array(compare_img)
    compare_img = cv2.cvtColor(compare_img, cv2.COLOR_RGB2BGR) 
    

    orb = cv2.ORB_create()
    kp2, des2 = orb.detectAndCompute(compare_img, None)

    matches_data = []
    for img_path in img_list:
        base_img = cv2.imread(img_path, 0)
        
        kp1, des1 = orb.detectAndCompute(base_img, None)

        bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)
        matches = bf.match(des1, des2)
        if matches:
            similarity = sum(match.distance for match in matches) / len(matches)
        else:
            similarity = 0

        matches_data.append((img_path, similarity))

    # sort matches by similarity score
    matches_data.sort(key=lambda x: x[1], reverse=True)
    
    # get top 5 matches
    top_matches = matches_data[:5]

    imgarray = []
    similarity_list = []
    # Generate HTML content for download
    html_content = "<html><body>"
    for i, (img_path, similarity) in enumerate(top_matches):
        base_img = cv2.imread(img_path)
        kp1, des1 = orb.detectAndCompute(base_img, None)

        bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)
        matches = bf.match(des1, des2)
        matches = sorted(matches, key=lambda x: x.distance)

        img3 = cv2.drawMatches(base_img, kp1, compare_img, kp2, matches[:10], None, flags=2)
        img3_rgb = cv2.cvtColor(img3, cv2.COLOR_BGR2RGB)
        
        

        # Save the image as BytesIO object
        img_bytes = io.BytesIO()
        Image.fromarray(img3_rgb).save(img_bytes, format='PNG')
        img_data = img_bytes.getvalue()
        imgarray.append(img_bytes)
        similarity_list.append(similarity)

        # Add the image to the HTML content
        html_content += f"<h3>ë¹„ìŠ·í•œ ì´ë¯¸ì§€ #{i+1} (ìœ ì‚¬ë„: {similarity:.2f})</h3>"
        html_content += f"<img src='data:image/png;base64,{base64.b64encode(img_data).decode()}'/><br><br>"

    html_content += "</body></html>"

    # Download button
    st.download_button("ê²°ê³¼ë¥¼ htmlë¡œ ë‹¤ìš´ë¡œë“œ ë°›ê¸° ", data=html_content, file_name="ë¶„ì„ ê²°ê³¼.html", mime="text/html")

    return  imgarray, similarity_list



    # # Display the matched images
    # for i, (img_path, similarity) in enumerate(top_matches):
    #     base_img = cv2.imread(img_path)
    #     kp1, des1 = orb.detectAndCompute(base_img, None)

    #     bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)
    #     matches = bf.match(des1, des2)
    #     matches = sorted(matches, key=lambda x: x.distance)

    #     img3 = cv2.drawMatches(base_img, kp1, compare_img, kp2, matches[:10], None, flags=2)
        
    #     # Create a Streamlit image object from the OpenCV image
    #     # st.write(f"Base image shape: {base_img.shape}")
    #     # st.write(f"Compare image shape: {compare_img.shape}")
    #     img_bytes = cv2.imencode('.png', img3)[1].tobytes()
    #     st.image(Image.open(io.BytesIO(img_bytes)), caption=f'ë¹„ìŠ·í•œ ì´ë¯¸ì§€ #{i+1} (ìœ ì‚¬ë„: {similarity:.2f})') # ë¹„í™œì„±í™”


       
        
        




def get_current_date():
    now = datetime.datetime.now()
    return now.strftime("%Y-%m-%d")






def intro():
    import streamlit as st
    def increase_visitor_count():
        current_date = get_current_date()
        file_path = os.path.join(VISITOR_COUNT_DIR, f"{current_date}.txt")

        if not os.path.exists(file_path):
            with open(file_path, "w") as f:
                f.write("0")

        with open(file_path, "r+") as f:
            count = int(f.read())
            count += 1
            f.seek(0)
            f.write(str(count))
    increase_visitor_count()
    st.write("# í”¼ë¶€ì•” ê²€ì‚¬ë¥¼ ìœ„í•œ í˜ì´ì§€ì— ì˜¨ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤ğŸ‘¨â€âš•ï¸")
    st.markdown("""
    **ğŸ‘ˆ ì‚¬ì´ë“œë°”ë¥¼ í´ë¦­í•´ì„œ** ë” ë§ì€ ì •ë³´ë¥¼ í™•ì¸í•˜ì„¸ìš”!
    """)
    st.sidebar.success("ì›í•˜ëŠ” ì •ë³´ë¥¼ í™•ì¸í•˜ì„¸ìš”")
    code = '''powered by Streamlit'''
    st.code(code, language='java')
    st.subheader("âš ï¸ ì˜í•™ì  ì§€ì‹ì„ ëŒ€ì²´í•˜ëŠ” ê²ƒì´ ì•„ë‹™ë‹ˆë‹¤ ")
    st.subheader("âš ï¸ ì ì¬ì ì¸ í”¼ë¶€ ë¬¸ì œë¥¼ ì‰½ê²Œ íŒŒì•…í•˜ëŠ” ë„ì›€ì„ ë°›ì„ ìˆ˜ ìˆë„ë¡ ë•ëŠ” ë„êµ¬ë¼ëŠ” ì ì— ìœ ì˜í•´ì•¼ í•©ë‹ˆë‹¤")
    st.markdown(
        """

        

        ### í˜ì´ì§€ ì œì‘ ë„ì›€ í¬ë ˆë”§

        - Check out [streamlit.io](https://streamlit.io)
        

        """)
    def get_visitor_count(date):
        file_path = os.path.join(VISITOR_COUNT_DIR, f"{date}.txt")

        if not os.path.exists(file_path):
            return 0

        with open(file_path, "r") as f:
            count = int(f.read())
            return count
    
    date = get_current_date()   
    user = get_visitor_count(date)
    now = datetime.datetime.now()
    
    def get_delta(now): #íŒŒë¼ë¯¸í„° ì—†ì• ê¸°, í˜¹ì€  get_current_date ìˆ˜ì •
        now = datetime.datetime.now()
        delta = now - datetime.timedelta(days= 1)
        delta = delta.strftime("%Y-%m-%d") # get_current_dateë‘ ê²¹ì¹¨
        
        return delta
        
    def user_check(date):
        delta = get_delta(date)
        if get_visitor_count(date) - get_visitor_count(delta) < 0:
            return 0
        else:
            return get_visitor_count(date) - get_visitor_count(delta)
    
    
    st.metric(label="ë°©ë¬¸ì ìˆ˜", value=user, delta=user_check(date))

    





def usage():
    import streamlit as st
    

    st.write("ì‚¬ìš©ë²• ì†Œê°œ")

def based_information():
    import streamlit as st
    
    
    st.markdown(f'# {list(page_names_to_funcs.keys())[1]}')
    
    st.header("ì´ ì•±ì—ì„œ íŒë³„ ê°€ëŠ¥í•œ ì•”ì˜ ì¢…ë¥˜ë“¤")
    st.write("- ['í¸í‰ ì„¸í¬ì•”'](https://en.wikipedia.org/wiki/Squamous-cell_carcinoma) ")
    st.write("- ['ê¸°ì € ì„¸í¬ì•”'](https://en.wikipedia.org/wiki/Basal-cell_carcinoma) ")
    st.write("- ['ì–‘ì„± ê°í™”ì¦'](https://en.wikipedia.org/wiki/Seborrheic_keratosis) ")
    st.write("- ['í”¼ë¶€ ì„¬ìœ ì¢…'](https://en.wikipedia.org/wiki/Dermatofibroma)  ")
    st.write("- ['ë©œë¼ë‹Œ ì„¸í¬ ëª¨ë°˜'](https://en.wikipedia.org/wiki/Melanocytic_nevus)  ")
    st.write("- ['í‘ìƒ‰ì¢…'](https://en.wikipedia.org/wiki/Melanoma) ")
    st.write("- ['í˜ˆê´€ ë³‘ë³€'](https://en.wikipedia.org/wiki/Vascular_anomaly) ")
    st.write(" ")




def testing():
    import streamlit as st
    
    import time
    import tensorflow as tf
    
    import numpy as np
    



    # Load TensorFlow Lite model
    interpreter = tf.lite.Interpreter(model_path="models/mobilenet_v1_1.0_224_quant.tflite")
    interpreter.allocate_tensors()
    interpreter = tf.lite.Interpreter(model_path="models/InceptionResNetV2Skripsi.tflite")
    interpreter.allocate_tensors()

    # Get input and output tensors
    input_details = interpreter.get_input_details()
    output_details = interpreter.get_output_details()


    # ì´ë¯¸ì§€ ì—…ìŠ¤ì¼€ì¼ë§ 


   # default upsc

    # Define a function to resize the input image
    # def resize_image(image):
    #     # Resize the image to 150x150 pixels
    #     resized_image = tf.image.resize(image, [150, 150])
        
    #     return resized_image.numpy()


    # replace upsc


    def resize_image(image):
        from PIL import Image
        # Get the original image shape
        original_shape = tf.shape(image)
        
        # Calculate the padding amounts
        height_pad = (original_shape[0] - 150) // 2
        width_pad = (original_shape[1] - 150) // 2
        
        # Pad the image
        padded_image = tf.pad(image, [[height_pad, height_pad], [width_pad, width_pad], [0, 0]])
        
        # Resize the padded image to 150x150 pixels
        resized_image = tf.image.resize(padded_image, [150, 150])

        
        return resized_image


    # Define a function to run inference on the TensorFlow Lite model
    def classify_image(image):
        # Pre-process the input image
        resized_image = resize_image(image)
        

        input_data = np.expand_dims(resized_image, axis=0).astype(np.float32)
        interpreter.set_tensor(input_details[0]['index'], input_data)
        
        
        
        # Run inference
        with st.spinner('ë¶„ì„ ì¤‘...'):
            start_time = time.time()
            interpreter.invoke()
            end_time = time.time()
            
        
        # Calculate the classification duration
        classifying_duration = end_time - start_time
       
        # Get the output probabilities
        output_data = interpreter.get_tensor(output_details[0]['index'])
        

        return output_data[0], classifying_duration

    # Define the labels for the 7 classes
    labels = ['í¸í‰ ì„¸í¬ì•”', 'ê¸°ì € ì„¸í¬ì•”', 'ì–‘ì„± ê°í™”ì¦', 'í”¼ë¶€ ì„¬ìœ ì¢…', 'í‘ìƒ‰ì¢…', 'ë©œë¼ë‹Œ ì„¸í¬ ëª¨ë°˜', 'í˜ˆê´€ ë³‘ë³€ì¦']

    from PIL import Image
    from urllib.error import URLError

    

    st.warning("ì´ë¯¸ì§€ ì œì¶œ ë°©ì‹ì„ ê³¨ë¼ì£¼ì„¸ìš”")

    upload = st.checkbox("íŒŒì¼ ì—…ë¡œë“œí•˜ê¸°")
    take = st.checkbox("ì‚¬ì§„ ì°ê¸°")
    if upload:
        image = st.file_uploader(label="íŒŒì¼ ì—…ë¡œë“œí•˜ê¸°", type=["jpg", "jpeg", "png"])
        if image is not None:
            # image_upscailing(image)
            image = np.array(Image.open(image).convert("RGB"))
            preresize = image
            st.code("ì‘ì—…ì— ì‚¬ìš©ëœ ì´ë¯¸ì§€", language= "java")
            st.image(image, width=150)

            # Run inference on the input image
            probs, classifying_duration = classify_image(image)

            
            # Display the classification duration
            st.success(f"ì†Œìš” ì‹œê°„: {classifying_duration:.4f} ì´ˆ", icon="âœ…")
            
            # Display the top 3 predictions
            top_3_indices = np.argsort(probs)[::-1][:3]
            
            st.write("ì˜ˆì¸¡ë˜ëŠ” ìƒìœ„ 3ê°œì˜ ì§•í›„:")
            for i in range(3):
                st.write("%d. %s (%.2f%%)" % (i + 1, labels[top_3_indices[i]], probs[top_3_indices[i]] * 100))
            st.divider()
            st.code("ìœ ì‚¬ì  ë¹„êµ", language='python')
            
            classification(preresize)
            st.button("ë‹¤ì‹œë³´ê¸°")
    elif take:
        image = st.camera_input(label="ì‚¬ì§„ ì°ê¸°", help="ì›¹ìº  ì§€ì›")
        if image is not None:
            
            image = np.array(Image.open(image).convert("RGB"))
            preresize = image
            

            # Run inference on the input image
            probs, classifying_duration = classify_image(image)

            
            # Display the classification duration
            st.success(f"ì†Œìš” ì‹œê°„: {classifying_duration:.4f} ì´ˆ")

            # Display the top 3 predictions
            top_3_indices = np.argsort(probs)[::-1][:3]
            
            st.write("ì˜ˆì¸¡ë˜ëŠ” ìƒìœ„ 3ê°œì˜ ì§•í›„:")
            for i in range(3):
                st.write("%d. %s (%.2f%%)" % (i + 1, labels[top_3_indices[i]], probs[top_3_indices[i]] * 100))
            with st.expander("ìœ ì‚¬ì  ë¹„êµí•´ë³´ê¸° "):
            
                st.header("ìœ ì‚¬ì  ë¹„êµ")
                imgarray, similarity_list = classification(preresize)
                
                # Convert HTML to image using imgkit
                

                wannasee = st.button("ê²°ê³¼ ì§ì ‘ ë³´ê¸°")
                if wannasee:
                    
                    collapse(imgarray, similarity_list)
                
            st.button("ë‹¤ì‹œë³´ê¸°")
def collapse(imgarray, similarity_list):
    import io
    from PIL import Image
    i = 0
    for img_bytes, similarity in zip(imgarray, similarity_list):
        st.image(Image.open(img_bytes), caption=f'ë¹„ìŠ·í•œ ì´ë¯¸ì§€ #{i+1} (ìœ ì‚¬ë„: {similarity:.2f})')
        i +=1 
            # ë‹¤ìš´ë¡œë“œ

        

# í˜ì´ì§€ êµ¬ì„± 

page_names_to_funcs = {
    "í™ˆ": intro,
    "í”¼ë¶€ì•”ì— ëŒ€í•œ ê¸°ë³¸ ì •ë³´": based_information,
    "ì‚¬ìš©ë²•": usage,
    "ê²€ì‚¬í•˜ê¸°": testing
}

page_name = st.sidebar.selectbox("ì›í•˜ëŠ” í˜ì´ì§€ë¥¼ ê³ ë¥´ì„¸ìš”", page_names_to_funcs.keys())
page_names_to_funcs[page_name]()